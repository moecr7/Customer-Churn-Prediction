# Churn Prediction Project

## Overview
This project predicts customer churn using an ensemble stacking model combining Random Forest, XGBoost, LightGBM, and Logistic Regression as a meta-classifier. The model is optimized with Optuna hyperparameter tuning and uses SMOTE for class balancing.

## Features
- Data preprocessing: missing value imputation, categorical encoding, scaling, PCA feature extraction
- Data balancing with SMOTE
- Stacking ensemble model with hyperparameter tuning (Optuna)
- Model evaluation with classification report, confusion matrix, and threshold optimization
- Saving/loading model and predictions for reproducibility

## Getting Started

### Prerequisites
- Python 3.8+
- Libraries: pandas, numpy, scikit-learn, imbalanced-learn, xgboost, lightgbm, optuna, matplotlib, seaborn, joblib

Install dependencies:
```bash
pip install -r requirements.txt
```
Project Structure
â”œâ”€â”€ X_train.csv
â”œâ”€â”€ X_test.csv
â”œâ”€â”€ y_train.csv
â”œâ”€â”€ y_test.csv
â””â”€â”€ y_pred_final.csv
â””â”€â”€ stacking_model.pkl

â””â”€â”€ import_data_visualization.ipynb
â””â”€â”€ preprocessing.ipynb
â””â”€â”€ modelling.ipynb
â””â”€â”€ evaluating.ipynb

â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

---

## ðŸš€ How to Run the Project

1. **Clone the repo:**

```bash
git clone https://github.com/moecr7/Customer-Churn-Prediction.git
cd Customer-Churn-Prediction
```
2.Install dependencies:

```bash
pip install -r requirements.txt
```


Run these notebooks in this order:

import_data_visualization.ipynb â€” import data and vizualization

preprocessing.ipynb â€” data cleaning, encoding, PCA

modelling.ipynb â€” train stacking model with Optuna tuning

evaluating.ipynb â€” ate model, tune threshold, save predictions and model

ðŸ§  Model Summary
Final model: StackingClassifier combining RandomForest, XGBoost, LightGBM

Meta-learner: Logistic Regression

Imbalanced data handled with SMOTE

Hyperparameters optimized with Optuna

ðŸ“¦ Outputs
Model saved at model/stacking_model.pkl

Data splits and predictions saved in data/

Evaluation metrics and plots generated in notebooks



Results
Achieved Recall score: 0.93

Confusion matrix and classification report available in evaluation notebook

Future Work
Add more feature engineering and data visualization

Experiment with other ensemble methods or neural networks

Deploy model using Flask/Django API

Contact
For questions or collaboration: [moeinbox55@gmail.com]

This project is part of my machine learning portfolio, showcasing data preprocessing, model tuning, and ensemble learning.
